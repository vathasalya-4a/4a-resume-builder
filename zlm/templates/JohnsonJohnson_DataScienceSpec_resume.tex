%==== PACKAGES AND OTHER DOCUMENT CONFIGURATIONS  ====%
\documentclass{resume} % Use the custom resume.cls style
\usepackage[left=0.25in,top=0.25in,right=0.25in,bottom=0.25in]{geometry} % Document margins
\usepackage[T1]{fontenc}
\usepackage{xcolor}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage{fontawesome} % For GitHub and LinkedIn symbols
\usepackage{textcomp} % For mobile phone and email symbols
% \usepackage[colorlinks=true, linkcolor=blue, citecolor=blue, urlcolor=blue]{hyperref}
\usepackage{xcolor}  % Required for defining custom colors
\usepackage{hyperref}
% Define your custom colors
% \definecolor{myblue}{RGB}{173, 216, 246}
% \definecolor{myblue}{RGB}{123, 176, 206}
\definecolor{myblue}{RGB}{0, 164, 218}

% Set hyperlink colors
\hypersetup{
    colorlinks=true,
    linkcolor=myblue,
    citecolor=myblue,
    urlcolor=myblue
}

\usepackage{hyperref}

%==== Headings ====%
\name{AMEY SADANAND BHILEGAONKAR} % Your name
\address{
{\faPhone} \href{tel:480{-}616{-}3980}{480{-}616{-}3980} \quad {\faEnvelope} \href{mailto:ameybhilegaonkar3@gmail.com}{ameybhilegaonkar3@gmail.com} \quad {\faGithub} \href{github.com/ameygoes}{github.com/ameygoes} \quad {\faLinkedin} \href{linkedin.com/in/amey{-}bhilegaonkar}{linkedin.com/in/amey{-}bhilegaonkar} }

\begin{document}

%===== WORK EXPERIENCE SECTION =====%
    \begin{rSection}{Work Experience}
                    \begin{rSubsection}
                {Data Science Intern}{June 2023 - August 2023}
                                    {\normalfont{\textit{BigCommerce}}}
                                {\normalfont{\textit{Austin, Texas}}}
                                    \item Designed and managed a large{-}scale Snowflake data retrieval pipeline for efficient data warehousing, enhancing data availability and resolving data{-}related issues.
                                    \item Implemented logistic regression and predictive models, boosting customer retention prediction accuracy by 12\% through advanced data analysis and modeling techniques.
                                    \item Collaborated with data infrastructure teams to ensure seamless data availability and resolve complex data{-}related issues, fostering a collaborative and solution{-}oriented environment.
                            \end{rSubsection}
                    \begin{rSubsection}
                {Data Engineer {-} II}{June 2019 - July 2022}
                                    {\normalfont{\textit{Publicis Sapient}}}
                                {\normalfont{\textit{Bangalore, India}}}
                                    \item Engineered complex ETL pipelines using Apache Spark, optimizing data extraction, transformation, and loading processes from diverse sources, resulting in enhanced data processing efficiency.
                                    \item Utilized distributed computing frameworks such as Apache Spark to manage large{-}scale data processing tasks, improving performance and resource utilization by 15\% through innovative data processing strategies.
                                    \item Enhanced database performance by optimizing queries and tuning indexes, leading to a 20\% reduction in query execution time and improved overall database efficiency.
                            \end{rSubsection}
            \end{rSection}

%==== EDUCATION SECTION ====%
\begin{rSection}{Education}
                        \textbf{Arizona State University, Tempe, USA} \hfill {August 2022 - May 2024} \\
                            {Masters of Science in Computer Science}
                         
             
         
                        \textbf{Pune Institute of Computer Technology, Pune, India} \hfill {July 2015 - May 2019} \\
                            {Bachelors of Engineering in Electronics and Telecommunications}
                         
             
         
    \end{rSection}

% ==== PROJECTS SECTION =====%
    \begin{rSection}{Projects}
                    \begin{rSubsection}
                                    {Search Engine for All file types {-} Opportunity Hackathon {-} Meta Sponsored}
                                {\normalfont{None - None}}{}{}
                                    \item Implemented Elasticsearch for rapid search responses, achieving millisecond response times.
                                    \item Transformed and indexed all file types as vector embeddings for efficient search capabilities.
                                    \item Led the development of Python FAST API for streamlined data access and retrieval.
                            \end{rSubsection}
                    \begin{rSubsection}
                                    {Scalable Data Processing Pipeline {-} Neo4J, Docker, Kafka and Minikube}
                                {\normalfont{None - None}}{}{}
                                    \item Designed and deployed a scalable data processing pipeline using Kubernetes, Kafka, Docker, and Neo4j.
                                    \item Orchestrated Kafka and Apache Zookeeper setup using Minikube for efficient data processing.
                                    \item Optimized data ingestion and processing into Neo4j, applying graph algorithms for exploration.
                            \end{rSubsection}
                    \begin{rSubsection}
                                    {Email Automation Marketing Tool}
                                {\normalfont{None - None}}{}{}
                                    \item Developed a robust email automation tool for job application outreach and networking.
                                    \item Integrated RESTful APIs for comprehensive contact database management from CRM tools.
                                    \item Demonstrated full{-}stack development skills with API design expertise.
                            \end{rSubsection}
                    \begin{rSubsection}
                                    {Speech Emotion Detection}
                                {\normalfont{None - None}}{}{}
                                    \item Enhanced emotion detection models by combining CNN and LSTM networks.
                                    \item Identified emotion{-}affecting attributes in voice through audio signal analysis.
                            \end{rSubsection}
            \end{rSection}

%==== TECHNICAL STRENGTHS SECTION ====%
    \begin{rSection}{Technical Skills}
        \begin{tabular}{ @{} l @{\hspace{1ex}} l }
                                \textbf{Programming Languages}: Python\\
                                \textbf{Cloud Platforms \& Databases}: SQL, GCP, AWS, Big Query\\
                                \textbf{Data Engineering}: SnowFlake, Spark, Pandas\\
                                \textbf{DevOps / SRE}: CI/CD, Git, Jenkins, Docker, Kubernetes\\
                        \textbf{Certifications:} 
                                            \href{None}{\textbf{Google Cloud Platform Associate Cloud Engineer}},\\
                                 
        \end{tabular}
    \end{rSection}
 

% ACHIEVEMENTS SECTION
    \begin{rSection}{Achievements}
        \begin{rSubsection}{}{}{}
                            \item Developed and implemented a predictive machine learning model that optimized financial forecasting accuracy by 15\% at XYZ Company.
                            \item Led a cross{-}functional team to automate data processing pipelines, reducing manual errors by 20\% and saving 100 hours per month.
                            \item Presented data{-}driven insights to senior stakeholders resulting in a 10\% increase in revenue for the Global Finance division at ABC Inc.
                            \item Received the 'Innovator of the Year' award for spearheading a project that leveraged AI techniques to streamline compliance adherence processes at DEF Corporation.
                    \end{rSubsection}
    \end{rSection}

\newcommand\myfontsize{\fontsize{0.1pt}{0.1pt}\selectfont} \myfontsize \color{white}
Data Science, Machine Learning, Python, R, Data Visualization, Cloud Computing, AI Techniques, Statistical Models, Data Processing, End{-}to{-}End Project Execution, Data Visualization Tools, Model Deployment, Workflow Orchestration, Generative AI, Compliance Adherence, Stakeholder Management, Data Science, Machine Learning, Python, R, Data Visualization, Cloud Computing, AI Techniques, Statistical Models, Data Processing, End{-}to{-}End Project Execution, Data Visualization Tools, Model Deployment, Workflow Orchestration, Generative AI, Compliance Adherence, Stakeholder Management, {artificial intelligence engineer, azure cognitive services exp, azure services, core azure services, azure cognitive and generative ai, genai, aws,  gcp, java, clean, efficient, maintainable code, react, front end, back end, ai solutions, data analysis, pretrained models, automl, software development principles, version control, testing, continuous integration and deployment, python, javascript, prompt engieering, frontend, backend, html, css, api, angular, development, machine learning, artificial intelligence, deep learning, data warehouse, data modeling, data extraction, data transformation, data loading, sql, etl, data quality, data governance, data privacy, data visualization, data controls, privacy, security, compliance, sla, aws, terabyte to petabyte scale data, full stack software development, cloud, security engineering, security architecture, ai/ml engineering, technical product management, microsoft office, google suite, visualization tools, scripting, coding, programming languages, analytical skills, collaboration, leadership, communication, presentation skills, computer vision, senior, ms or ph.d., 3d pose estimation, slam, robotics, object tracking, real-time systems, scalability, autonomy, robotic process automation, java, go, matlab, devops, ci/cd, programming, computer vision, data science, machine learning frameworks, deep learning toolsets, problem-solving, individual contributor, statistics, risk assessments, statistical modeling, apis, technical discussions, cross-functional teams}

\end{document}